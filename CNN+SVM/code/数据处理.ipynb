{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fb8f91e",
   "metadata": {},
   "source": [
    "### 1. 数据基本处理\n",
    "- 先把数据和标签读取进来，再进行基本的删除工作，有：删除丢失数据，删除错误数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e88d2647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from util import *\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcf8be09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3993, 16384)\n",
      "(3993,)\n"
     ]
    }
   ],
   "source": [
    "# 删除丢失数据\n",
    "# 得到标签列表和图片数据\n",
    "label_Path = '../face/'\n",
    "img_Path = '../face/rawdata/'\n",
    "label_list = get_label_list(label_Path)\n",
    "# 得到图片数据，对于标签缺失的数据直接删除\n",
    "# get_img_data(img_Path, label_list)\n",
    "\n",
    "# 得到删除后标签的数据，对于标签缺失的数据直接删除\n",
    "labe_dict = []\n",
    "for _dict in label_list :           \n",
    "    if _dict['missing'] != 'true' :\n",
    "        labe_dict.append(_dict)\n",
    "label_list = labe_dict\n",
    "\n",
    "# 加载图片数据，并输出此时 数据和标签 的大小\n",
    "img_save_Path = './ImgData/img_old.npy'\n",
    "img_list = np.load(img_save_Path) # (3993*(128*128))\n",
    "print(img_list.shape)\n",
    "print(np.array(labe_dict).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd6c0467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据错误图片对应的id为： ['3283', '3860', '3861', '3862', '3883', '4125', '4146', '4237', '4267', '4295', '4335', '4354', '4429', '4452', '4498', '4566', '4637', '4679', '4710', '4779', '4908', '4992', '5076', '5113', '2099', '2100', '2101', '2102', '2103', '2104', '2105', '2106']\n",
      "(3961, 16384)\n",
      "(3961,)\n"
     ]
    }
   ],
   "source": [
    "# 删除错误数据\n",
    "img_list, label_list = DeleteBadData(img_list, label_list)\n",
    "print(img_list.shape)\n",
    "print(np.array(label_list).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6096ad12",
   "metadata": {},
   "source": [
    "### 2. 保存处理好的图像数据，原图像数据和上采样后的图像数据\n",
    "\n",
    "因为我们使用resnet50作为迁移学习模型，其要求图像为（224，224），故需要把（128，128）的图像进行上采样放大为原来的两倍，变为（256，256），方便使用resnet50模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20cd2878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    }
   ],
   "source": [
    "# 按性别名称保存jpg图像到face_data/sex_origina文件夹中\n",
    "# 保存的图名为 '标签.序号.jpg' ，如 'female.00001.jpg'\n",
    "# 图片大小为（128，128）\n",
    "save_Path = '../face_data/sex_original/img/'\n",
    "id_to_indx = []\n",
    "indx = 1\n",
    "for i in range(img_list.shape[0]) :\n",
    "    sex = label_list[i]['sex']\n",
    "    img = img_list[i]\n",
    "    img = img.reshape(128,128)\n",
    "    img = Image.fromarray(img)\n",
    "    s=\".%05d\"%indx\n",
    "    img.save(save_Path + sex + s + '.jpg')\n",
    "    id = label_list[i]['id']\n",
    "    id_to_indx.append(id)\n",
    "    indx += 1\n",
    "np.save( '../face_data/sex_original/id_to_indx.npy', np.array(id_to_indx))\n",
    "print('success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d68885f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3961"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_list.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9713cf4f",
   "metadata": {},
   "source": [
    "- 把这3961个图像上采样变为（256，256）\n",
    "- 采用双线性插值（bilinear）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6fb3f293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5f84f5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    }
   ],
   "source": [
    "# 把上采样后的jpg图像到face_data/sex_upsample文件夹中\n",
    "# 保存的图名为 '标签.序号.jpg' ，如 'female.00001.jpg'\n",
    "# 图片大小为（256，256）\n",
    "def img_upsample(img_list, label_list, save_Path='../face_data/sex_upsample/'):\n",
    "    id_to_indx = []\n",
    "    indx = 1\n",
    "    Bilinear2d = nn.UpsamplingBilinear2d(scale_factor=2) # 双线性插值类方法\n",
    "    for i in range(img_list.shape[0]) :\n",
    "        sex = label_list[i]['sex']\n",
    "        img = img_list[i]\n",
    "        img = img.reshape(128,128)\n",
    "        img = torch.from_numpy(img).view(1, 1, 128, 128) # 转换为tensor\n",
    "        img = Bilinear2d(img.float())        # 上采样只能在tensor浮点数运行\n",
    "        img = img.numpy().reshape(256,256)   # 转换为numpy\n",
    "        img = Image.fromarray(np.uint8(img)) # 图片要使用np.uint8\n",
    "        s=\".%05d\"%indx\n",
    "        img.save(save_Path + 'img/' + sex + s + '.jpg')\n",
    "        id = label_list[i]['id']\n",
    "        id_to_indx.append(id)\n",
    "        indx += 1\n",
    "    np.save( save_Path + 'id_to_indx.npy', np.array(id_to_indx))\n",
    "    print('success')\n",
    "    \n",
    "img_upsample(img_list, label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7ffe6a",
   "metadata": {},
   "source": [
    "- 对比展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "926397eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取img_list第一幅图像进行展示\n",
    "img1 = img_list[0].reshape(128,128)\n",
    "img1 = torch.from_numpy(img1).view(1, 1, 128, 128)\n",
    "\n",
    "# 上采样类\n",
    "Bilinear2d = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "lingNearest2d = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "\n",
    "img_b = Bilinear2d(img1.float())\n",
    "img_l = lingNearest2d(img1.float())\n",
    "\n",
    "# 将数组转为图像的过程中，数组中的数据是浮点型（F）无法转为图像，\n",
    "# 因此需要改变image的类型\n",
    "img_b = img_b.numpy().reshape(256,256)   # 转换为numpy\n",
    "img_l = img_l.numpy().reshape(256,256) \n",
    "\n",
    "img_b_RGB = Image.fromarray(img_b).convert('RGB') # 转换为RGB\n",
    "img_b = Image.fromarray(np.uint8(img_b)) # 灰度图片要使用np.uint8\n",
    "img_l = Image.fromarray(np.uint8(img_l)) \n",
    "\n",
    "im = img_list[0].reshape(128,128)  # 原图\n",
    "im = Image.fromarray(im)\n",
    "\n",
    "# 保存图片\n",
    "root_path = '../face_data/sex_上采样后的对比图/'\n",
    "img_b_RGB.save(root_path + '上采样_Bilinear2d_RGB.jpg')\n",
    "img_b.save(root_path + '上采样_Bilinear2d.jpg')\n",
    "img_l.save(root_path + '上采样_lingNearest2d.jpg')\n",
    "im.save(root_path + '原图.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abdafb6",
   "metadata": {},
   "source": [
    "### 3. 按照性别划分子文件夹，分别保存男和女的人脸图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "837e6924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from shutil import copy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4d684067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取保存好的上采样图像\n",
    "data_path = '../face_data/sex_upsample/img/'\n",
    "img_dirlist = os.listdir(data_path) # 获取该目录下图像名称列表\n",
    "\n",
    "female_save_path = '../face_data/sex_upsample/Female_Male/female/'\n",
    "male_save_path = '../face_data/sex_upsample/Female_Male/male/'\n",
    "for img_name in img_dirlist:\n",
    "    img_lable = img_name.split('.')[0]\n",
    "    if img_lable == 'female':\n",
    "        copy2(data_path + img_name, female_save_path) # 复制文件\n",
    "    else:\n",
    "        copy2(data_path + img_name, male_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb276fe",
   "metadata": {},
   "source": [
    "### 4. 划分训练集、验证集、测试集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef820bbf",
   "metadata": {},
   "source": [
    "- 安照torch的数据保存要求保存好图像数据。\n",
    "- 把图像按8：1：1保存到训练集、验证集、测试集。每个集中分别把同一类别的图像保存到同一文件夹中，这里共有两个文件夹，female和male。\n",
    "- 这样标签也能很方便的保存下来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "af07645b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 调用util中的data_set_split函数来划分训练集、验证集、测试集\n",
    "# from util import data_set_split\n",
    "# src_data_folder = '../face_data/sex_upsample/Female_Male' # 源文件\n",
    "# target_data_folder = '../face_data/sex/' # 目标文件\n",
    "# data_set_split(src_data_folder, target_data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8d145358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from shutil import copy2\n",
    "\n",
    "def data_set_split(src_data_folder, target_data_folder, train_scale=0.8, val_scale=0.1, test_scale=0.1):\n",
    "\n",
    "    '''\n",
    "    读取源数据文件夹，生成划分好的文件夹，分为trian、valid、test三个文件夹进行\n",
    "    :param src_data_folder: 源文件夹\n",
    "    :param target_data_folder: 目标文件夹\n",
    "    :param train_scale: 训练集比例\n",
    "    :param val_scale: 验证集比例\n",
    "    :param test_scale: 测试集比例\n",
    "    :return:\n",
    "    '''\n",
    "\n",
    "    print(\"开始数据集划分\")\n",
    "    class_names = os.listdir(src_data_folder)\n",
    "    # 在目标目录下创建文件夹\n",
    "    split_names = ['train', 'valid', 'test']\n",
    "    for split_name in split_names:\n",
    "        split_path = os.path.join(target_data_folder, split_name)\n",
    "        if os.path.isdir(split_path):\n",
    "            pass\n",
    "        else:\n",
    "            os.mkdir(split_path)\n",
    "        # 然后在split_path的目录下创建类别文件夹\n",
    "        for class_name in class_names:\n",
    "            class_split_path = os.path.join(split_path, class_name)\n",
    "            if os.path.isdir(class_split_path):\n",
    "                pass\n",
    "            else:\n",
    "                os.mkdir(class_split_path)\n",
    "\n",
    "    # 按照比例划分数据集，并进行数据图片的复制\n",
    "    # 首先进行分类遍历\n",
    "    for class_name in class_names:\n",
    "        current_class_data_path = os.path.join(src_data_folder, class_name)\n",
    "        current_all_data = os.listdir(current_class_data_path)\n",
    "        current_data_length = len(current_all_data)\n",
    "        current_data_index_list = list(range(current_data_length))\n",
    "        random.shuffle(current_data_index_list)\n",
    "\n",
    "        train_folder = os.path.join(os.path.join(target_data_folder, 'train'), class_name)\n",
    "        val_folder = os.path.join(os.path.join(target_data_folder, 'valid'), class_name)\n",
    "        test_folder = os.path.join(os.path.join(target_data_folder, 'test'), class_name)\n",
    "        train_stop_flag = current_data_length * train_scale\n",
    "        val_stop_flag = current_data_length * (train_scale + val_scale)\n",
    "        current_idx = 0\n",
    "        train_num = 0\n",
    "        val_num = 0\n",
    "        test_num = 0\n",
    "        for i in current_data_index_list:\n",
    "            src_img_path = os.path.join(current_class_data_path, current_all_data[i])\n",
    "            if current_idx <= train_stop_flag:\n",
    "                copy2(src_img_path, train_folder)\n",
    "                # print(\"{}复制到了{}\".format(src_img_path, train_folder))\n",
    "                train_num = train_num + 1\n",
    "            elif (current_idx > train_stop_flag) and (current_idx <= val_stop_flag):\n",
    "                copy2(src_img_path, val_folder)\n",
    "                # print(\"{}复制到了{}\".format(src_img_path, val_folder))\n",
    "                val_num = val_num + 1\n",
    "            else:\n",
    "                copy2(src_img_path, test_folder)\n",
    "                # print(\"{}复制到了{}\".format(src_img_path, test_folder))\n",
    "                test_num = test_num + 1\n",
    "\n",
    "            current_idx = current_idx + 1\n",
    "\n",
    "        print(\"*********************************{}*************************************\".format(class_name))\n",
    "        print(\n",
    "            \"{}类按照{}：{}：{}的比例划分完成，一共{}张图片\".format(class_name, train_scale, val_scale, test_scale, current_data_length))\n",
    "        print(\"训练集{}：{}张\".format(train_folder, train_num))\n",
    "        print(\"验证集{}：{}张\".format(val_folder, val_num))\n",
    "        print(\"测试集{}：{}张\".format(test_folder, test_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "66f5adf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始数据集划分\n",
      "*********************************female*************************************\n",
      "female类按照0.8：0.1：0.1的比例划分完成，一共1566张图片\n",
      "训练集../face_data/sex/train\\female：1253张\n",
      "验证集../face_data/sex/valid\\female：157张\n",
      "测试集../face_data/sex/test\\female：156张\n",
      "*********************************male*************************************\n",
      "male类按照0.8：0.1：0.1的比例划分完成，一共2395张图片\n",
      "训练集../face_data/sex/train\\male：1917张\n",
      "验证集../face_data/sex/valid\\male：239张\n",
      "测试集../face_data/sex/test\\male：239张\n"
     ]
    }
   ],
   "source": [
    "src_data_folder = '../face_data/sex_upsample/Female_Male' # 源文件\n",
    "target_data_folder = '../face_data/sex/' # 目标文件\n",
    "data_set_split(src_data_folder, target_data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb410ae",
   "metadata": {},
   "source": [
    "- 数据预处理完成"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch(gpu)",
   "language": "python",
   "name": "06-pytorch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
